# -*- coding: utf-8 -*-
"""chat_floria.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yxAahDnL2W14k5429pwFfSl7FNQnJBrf
"""

# @title GDriveã®æ¥ç¶š
from google.colab import drive
drive.mount('/content/drive')

# @title ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®èª­ã¿è¾¼ã¿
!pip install -q floria_snippets

# @title ## Floria Chat â€” Stable Edition (multiline input)
import os, requests, textwrap, re, json, datetime, glob
from dotenv import load_dotenv
from floria_snippets import SYSTEM_PROMPT, STARTER_USER_MSG

# ====== è¨­å®š ======
load_dotenv('/content/drive/MyDrive/app/floria/secret.env')

_raw = os.getenv("LLAMA_BASE_URL", "https://openrouter.ai/api/v1").rstrip("/")
BASE = _raw + ("/v1" if _raw.endswith("/api") else "/api/v1") if not _raw.endswith("/api/v1") else _raw

MODEL = os.getenv("LLAMA_MODEL", "meta-llama/llama-3.1-70b-instruct")
API   = os.getenv("LLAMA_API_KEY")
if not API:  raise RuntimeError("LLAMA_API_KEY ãŒæœªè¨­å®šã§ã™ã€‚secret.env ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
if not MODEL:raise RuntimeError("LLAMA_MODEL ãŒæœªè¨­å®šã§ã™ã€‚secret.env ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

JUST_LOADED = False  # â† ã‚°ãƒ­ãƒ¼ãƒãƒ«åˆæœŸåŒ–ï¼ˆä»–ã¨åŒã˜éšå±¤ã«ï¼‰

# ====== ä¼šè©±å±¥æ­´ ======
STYLE_GUARD = "å‡ºåŠ›ã¯ç´ ã®æ–‡ç« ã€‚è¡Œé ­ã«è£…é£¾è¨˜å·ï¼ˆ*,ãƒ»,â€¢,â˜… ãªã©ï¼‰ã‚’ä»˜ã‘ãªã„ã€‚è¦‹å‡ºã—ã‚„ç®‡æ¡æ›¸ãã¯ä½¿ã‚ãªã„ã€‚"
messages = [
    {"role":"system","content": SYSTEM_PROMPT + "\n" + STYLE_GUARD},
    {"role":"user","content": STARTER_USER_MSG}
]

# --- è¡¨ç¤ºè¨­å®š ---
WRAP = 30

# --- è¡Œé ­ã‚´ãƒŸé™¤å» ---
CLEAN_HEAD = re.compile(r"^[\s\ufeff\*ï½¥ãƒ»â€¢â˜…â˜†#,'â€™\"`\-]+")
def clean_reply(text: str) -> str:
    if not text: return text
    text = text.replace("*',*", "")
    lines = [CLEAN_HEAD.sub("", line) for line in text.splitlines()]
    return "\n".join(lines).strip()

def show_recent(n: int = 10):
    """ç›´è¿‘ n ç™ºè¨€ï¼ˆuser/assistantã®ã¿ï¼‰ã‚’æ™‚ç³»åˆ—ã§è¡¨ç¤º"""
    dialog = [m for m in messages if m.get("role") in ("user", "assistant")]
    recent = dialog[-n:]  # æ™‚ç³»åˆ—ã®ã¾ã¾æœ«å°¾nä»¶
    if not recent:
        print("ï¼ˆè¡¨ç¤ºã§ãã‚‹ä¼šè©±ãŒã‚ã‚Šã¾ã›ã‚“ï¼‰\n")
        return
    print(f"ğŸ§¾ æœ€è¿‘ã®ä¼šè©±ï¼ˆ{len(recent)}ä»¶ï¼‰\n")
    for m in recent:
        role = m["role"]
        txt = m.get("content", "")
        if role == "assistant":
            txt = clean_reply(txt)
        wrapped = textwrap.fill(txt.strip(), width=WRAP)
        prefix = "ã‚ãªãŸ: " if role == "user" else "â„ï¸ãƒ•ãƒ­ãƒ¼ãƒªã‚¢: "
        print(prefix + "\n" + wrapped + "\n")

def show_assistant(text: str):
    text = clean_reply(text)
    print("â„ï¸ãƒ•ãƒ­ãƒ¼ãƒªã‚¢:\n" + textwrap.fill(text, width=WRAP) + "\n")

def multiline_input(prompt="ã‚ãªãŸ: "):
    """è¤‡æ•°è¡Œå…¥åŠ›â†’ç©ºè¡Œã§é€ä¿¡ã€‚/bye çµ‚äº†ã€‚/wrap N æŠ˜è¿”ã—å¹…å¤‰æ›´ã€‚"""
    global WRAP
    print(prompt)
    lines = []
    while True:
        line = input()
        if line == "":  # ç©ºè¡Œã§é€ä¿¡
            break
        low = line.strip().lower()
        if not lines and low.startswith("/wrap "):
            try:
                WRAP = max(20, int(low.split()[1]))
                print(f"â†º æŠ˜ã‚Šè¿”ã—å¹…ã‚’ {WRAP} ã«å¤‰æ›´ã—ã¾ã—ãŸã€‚\n")
            except:
                print("â†º /wrap N ã§æ•°å€¤ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ï¼ˆä¾‹ï¼š/wrap 40ï¼‰\n")
            return ""    # ã“ã®å›ã¯é€ã‚‰ãªã„
        lines.append(line)
    return "\n".join(lines).strip()

# ====== ä¼šè©±ãƒ­ã‚° ä¿å­˜/èª­è¾¼/ãƒªã‚»ãƒƒãƒˆ ======
LOG_DIR = "/content/drive/MyDrive/app/floria/chat_logs"
os.makedirs(LOG_DIR, exist_ok=True)

def save_log():
    ts = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    path = f"{LOG_DIR}/floria_{ts}.json"
    with open(path, "w", encoding="utf-8") as f:
        json.dump(messages, f, ensure_ascii=False, indent=2)
    print(f"ğŸª¶ ä¼šè©±ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {path}\n")

def load_log():
    global JUST_LOADED
    files = sorted(glob.glob(f"{LOG_DIR}/floria_*.json"))
    if not files:
        print("ï¼ˆä¿å­˜ã•ã‚ŒãŸä¼šè©±ãƒ­ã‚°ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼‰\n")
        return
    print("ğŸ“œ ä¿å­˜æ¸ˆã¿ãƒ­ã‚°ä¸€è¦§ï¼š")
    for i, f in enumerate(files, 1):
        print(f"{i:02d}: {os.path.basename(f)}")
    sel = input("\nç•ªå·ã‚’å…¥åŠ›ï¼ˆã‚­ãƒ£ãƒ³ã‚»ãƒ«ã¯ç©ºEnterï¼‰: ").strip()
    if not sel: return
    try:
        idx = int(sel) - 1
        if 0 <= idx < len(files):
            with open(files[idx], "r", encoding="utf-8") as f:
                loaded = json.load(f)
            messages.clear()
            messages.extend(loaded)
            JUST_LOADED = True   # â† ã“ã“ã‚’è¿½åŠ 
            print(f"â†º ä¼šè©±ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {files[idx]}\n")
            show_recent(10)
        else:
            print("ï¼ˆç•ªå·ãŒç¯„å›²å¤–ã§ã™ï¼‰\n")
    except Exception as e:
        print(f"ï¼ˆèª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}ï¼‰\n")

def reset_dialog():
    messages.clear()
    messages.extend([
        {"role":"system","content": SYSTEM_PROMPT + "\n" + STYLE_GUARD},
        {"role":"user","content": STARTER_USER_MSG}
    ])
    print("â†º ä¼šè©±ã‚’ãƒªã‚»ãƒƒãƒˆã—ã¾ã—ãŸã€‚\n")

# ====== ãƒ•ãƒ­ãƒ¼ãƒªã‚¢ã®è¿”ç­”ï¼ˆ_last_user è¨˜éŒ²ã¤ãï¼‰ ======
_last_user = None
def floria_say(user_text, temperature=0.7, max_tokens=300):
    global _last_user, JUST_LOADED
    if not user_text:
        return ""

    _last_user = user_text
    messages.append({"role":"user","content": user_text})

    try:
        resp = requests.post(
            f"{BASE}/chat/completions",
            headers={
                "Authorization": f"Bearer {API}",
                "Content-Type": "application/json",
                "HTTP-Referer": "https://colab.research.google.com",
                "X-Title": "Floria-Colab-Release"
            },
            json={
                "model": MODEL,
                "messages": messages,
                "temperature": temperature,
                "max_tokens": max_tokens
            },
            timeout=60
        )
        try:
            data = resp.json()
        except Exception:
            data = None

        if resp.status_code != 200:
            err_msg = (data.get("error", {}).get("message") or data.get("message") or resp.text[:500]) if isinstance(data, dict) else resp.text[:500]
            a = f"ï¼ˆã”ã‚ã‚“ãªã•ã„ã€å†·ãŸã„éœ§ã§å£°ãŒå±Šãã¾ã›ã‚“â€¦ {resp.status_code}: {err_msg}ï¼‰"
        else:
            a = data["choices"][0]["message"]["content"] if isinstance(data, dict) and data.get("choices") else f"ï¼ˆè¿”äº‹ã®å½¢ãŒå‡ã£ã¦ã—ã¾ã£ãŸã¿ãŸã„â€¦ï¼š{str(data)[:200]}ï¼‰"

    except requests.exceptions.Timeout:
        a = "ï¼ˆå›ç·šãŒå‡ã‚Šã¤ã„ã¦ã—ã¾ã£ãŸã¿ãŸã„â€¦å°‘ã—ã—ã¦ã‹ã‚‰ã‚‚ã†ä¸€åº¦ãŠé¡˜ã„ã—ã¾ã™ï¼‰"
    except Exception as e:
        a = f"ï¼ˆæ€ã‚ã¬æ¸¦ã«å·»ãè¾¼ã¾ã‚Œã¾ã—ãŸâ€¦: {e}ï¼‰"

    messages.append({"role":"assistant","content": a})
    show_assistant(a)
    if not JUST_LOADED:     # ãƒ­ãƒ¼ãƒ‰ç›´å¾Œã ã‘è‡ªå‹•ä¿å­˜ã‚¹ã‚­ãƒƒãƒ—
        save_log()
    JUST_LOADED = False
    return a
# ====== å¯¾è©±ãƒ«ãƒ¼ãƒ— ======
print("ğŸ§Š ãƒ•ãƒ­ãƒ¼ãƒªã‚¢ã¨ä¼šè©±ã‚’å§‹ã‚ã¾ã™ã€‚\nãƒ»è¤‡æ•°è¡ŒOKï¼**ç©ºè¡Œã§é€ä¿¡**ï¼/bye çµ‚äº†ï¼/wrap N ã§æŠ˜è¿”ã—å¹…\n"
      "ãƒ»/save ä¿å­˜ ï¼ /load èª­è¾¼ ï¼ /clear ãƒªã‚»ãƒƒãƒˆ ï¼ /retry ç›´å‰å†é€\n")
while True:
    t = multiline_input("ã‚ãªãŸ: ")
    cmd = t.strip().lower()

    if cmd == "/bye":
        print("ï¼ˆã¾ãŸã­ï¼‰"); break
    if cmd == "/save":
        save_log(); continue
    if cmd == "/load":
        load_log(); continue
    if cmd == "/clear":
        reset_dialog(); continue
    if cmd == "/retry":
        if _last_user: floria_say(_last_user)
        else: print("ï¼ˆç›´å‰ã®å…¥åŠ›ãŒã‚ã‚Šã¾ã›ã‚“ï¼‰")
        continue
    if cmd.startswith("/recent"):
        try:
            n = int(cmd.split()[1])
        except:
            n = 10
        show_recent(n)
        continue
    if not t:
        continue

    floria_say(t)

import json

path = "/content/drive/MyDrive/app/floria/chat_logs/floria_20251031_163047.json"
with open(path, "r", encoding="utf-8") as f:
    data = json.load(f)

print(f"å…¨ãƒ­ã‚°ä»¶æ•°: {len(data)}")
print("æœ«å°¾2ä»¶:")
for m in data[-2:]:
    print(f"[{m['role']}] {m['content'][:100]}...")